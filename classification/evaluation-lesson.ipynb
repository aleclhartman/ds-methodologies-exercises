{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Evaluation\n",
    "\n",
    "- Different domains have different needs\n",
    "    - iPhone face id -- high precision\n",
    "    - Fraud detection -- high recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction\n",
       "0     coffee  no coffee\n",
       "1  no coffee  no coffee\n",
       "2  no coffee     coffee\n",
       "3     coffee     coffee\n",
       "4     coffee     coffee\n",
       "5     coffee     coffee\n",
       "6  no coffee  no coffee\n",
       "7     coffee  no coffee"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'actual': ['coffee', 'no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'coffee'],\n",
    "    'prediction': ['no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'no coffee'],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Confusion Matrix is Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>coffee</th>\n",
       "      <th>no coffee</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no coffee</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction  coffee  no coffee\n",
       "actual                       \n",
       "coffee           3          2\n",
       "no coffee        1          2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.actual, df.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TP: predicted coffee + actual is coffee\n",
    "- FP: predicted coffee, but they didn't want coffee\n",
    "- FN: predicted no coffee, but really they wanted coffee\n",
    "- TN: predicted no coffee + actual is no coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our choice of positive and negative is arbitrary\n",
    "- the labels / layout of the confusion matrix vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **accuracy**: (TP + TN) / (TP + TN + FP + FN)\n",
    "    - (3 + 2) / (3 + 1 + 2 + 2) = 62.5%\n",
    "- **precision**: TP / (TP + FP)\n",
    "    - 3 / (3 + 1) = 75%\n",
    "    - FP is more costly than FN; in fact precision does not take into account FN at all\n",
    "- **recall**: TP / (TP + FN)\n",
    "    - 3 / (3 + 2) = 60%\n",
    "    - FN is more costly than a FP; in fact precision does not take into account FP at all\n",
    "\n",
    "Imagine you're bringing coffee to meeting, which metric would we choose? It depends\n",
    "\n",
    "Outcomes:\n",
    "- FP: Buy coffee for someone who won't drink it\n",
    "- FN: Don't buy coffee for someone who would have drank it\n",
    "- TP: Buy coffee for someone who will drink it\n",
    "- TN: Don't buy coffee for someone who wouldn't drink it\n",
    "\n",
    "- lola: really good coffee, but expensive\n",
    "    - cost of a FP is a higher than FN\n",
    "    - precision is better here because buying a cup of coffee for someone who won't drink it is expensive\n",
    "    - We want to be sure about our positive preditions\n",
    "- taco cabana: bad coffee, but cheap\n",
    "    - cost of a FN is higher than FP\n",
    "    - recall because the coffee is cheap, its not bad to buy a cheap coffee for someone who won't drink it; worse to not get someone coffee who wanted it\n",
    "- meeting with super important client\n",
    "    - cost of NF is higher, because they might be offended if we don't get them coffee\n",
    "    - cost of FN == not signing a contract\n",
    "    - recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just don't buy coffee or buy coffee for everyone? == Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coffee       5\n",
       "no coffee    3\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"baseline\"] = \"coffee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction baseline\n",
       "0     coffee  no coffee   coffee\n",
       "1  no coffee  no coffee   coffee\n",
       "2  no coffee     coffee   coffee\n",
       "3     coffee     coffee   coffee\n",
       "4     coffee     coffee   coffee\n",
       "5     coffee     coffee   coffee\n",
       "6  no coffee  no coffee   coffee\n",
       "7     coffee  no coffee   coffee"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# foundational code\n",
    "# model accuracy\n",
    "(df.actual == df.prediction).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "(df.actual == df.baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision -- how good are our positive predictions?\n",
    "# precision -- model performance | predicted positive\n",
    "subset = df[df.prediction == \"coffee\"]\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall -- how often do we get the actual positive cases?\n",
    "# recall -- model performance | actual positive\n",
    "subset = df[df.actual == \"coffee\"]\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision baseline\n",
    "subset = df[df.baseline == \"coffee\"]\n",
    "(subset.actual == subset.baseline).mean() # precision is the same as accuracy in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall baseline\n",
    "subset = df[df.actual == \"coffee\"]\n",
    "(subset.actual == subset.baseline).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Example:\n",
    "\n",
    "Predict whether an email is spam or not.\n",
    "\n",
    "- positive case: spam\n",
    "- negative case: not spam\n",
    "\n",
    "Outcome:\n",
    "\n",
    "- TP: Predict message is spam and it really is\n",
    "- FP: Predict message is spam and it's really not\n",
    "- FN: Predict message is not spam and it's really is\n",
    "- TN: Predict message is not spam, and it really is spam\n",
    "\n",
    "Which has a higher cost, a false postive or false negative?\n",
    "\n",
    "FP - it is  **_bad_** to put Bill in accounting's email in your spam folder\n",
    "\n",
    "Precision: because we want to be certain a message really is spam when we send it to the spam folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Example:\n",
    "\n",
    "Predict whether an emali is a phishing attempt. When we predict positive, show an additional banner\n",
    "\n",
    "- positive case: phishing attempt\n",
    "- negative case: legit email\n",
    "\n",
    "Outcomes:\n",
    "\n",
    "- FP: Show a warning about phishing on a legit email\n",
    "- TP: Show a warning about phishing and it really is\n",
    "- FN: Don't show a warning on a phishing email\n",
    "- TN: Don't show a warning on a legit email\n",
    "\n",
    "Which has the highest cost? FN: not showing a warning on a phishing email\n",
    "\n",
    "The cost of showing a banner on a legit email is less than not showing a banner on a phishing email.\n",
    "\n",
    "Optimize for recall in out phishing detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does \"positive\" mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = \"coffee\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "In short:\n",
    "\n",
    "- optimize for **precision** when you want to be sure about your positive predictions\n",
    "- optimize for **recall** when you don't want to miss actual positive cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
